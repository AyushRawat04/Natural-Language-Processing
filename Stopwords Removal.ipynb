{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e217292a",
   "metadata": {},
   "source": [
    "# Stop Words Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199e510c",
   "metadata": {},
   "source": [
    "Assume project to identify the category of a news article as one of politics, sports, business, and other.\n",
    "For this project, suppose we have already used an efficient sentence segmenter and word tokenizer.\n",
    "\n",
    "Some of the words in the corpus such as a, an, the, of, in, etc., do not add much value to the information that is required for the classification.\n",
    "\n",
    "We typically remove such words, called stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53add8b7",
   "metadata": {},
   "source": [
    "### Why remove stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d7581",
   "metadata": {},
   "source": [
    "stop words are present in abundance.\n",
    "\n",
    "remove low-level information from the content to focus on important information.\n",
    "\n",
    "By removing these words, we retain most of the important information so no negative consequences our model.\n",
    "\n",
    "The cleaning of stop words helps us reduce the size of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1d2019",
   "metadata": {},
   "source": [
    "### Why not remove stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9625377",
   "metadata": {},
   "source": [
    "The decision to remove the stop words depends upon the task and goal that we want to achieve.\n",
    "For sentiment analysis, on several occasions, the removal of stop words may be disastrous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a45907b",
   "metadata": {},
   "source": [
    "## Stop Word Libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a11b2e6",
   "metadata": {},
   "source": [
    "### 1. NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a0a3275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e51ff7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e6227b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d927a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_nltk = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e426b49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords_nltk)  # print all nltk stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc7cb283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of stopwords in nltk library is :  179\n"
     ]
    }
   ],
   "source": [
    "print(\"total number of stopwords in nltk library is : \",len(stopwords_nltk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ed214e",
   "metadata": {},
   "source": [
    "#### Let’s remove the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a74363b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Doglapan by Ashneer Grover is hands down one of the most interesting books I've ever read and now my favourite.\n",
    "Ashneer's life according to me is a full-blown masala Bollywood story, and that's one of the best parts of this book! Nowhere does he shy away from admitting his vulnerability, his failures, or his insecurities.\n",
    "His book maybe titled as \"Doglapan\", but has a lot of \"Sachhai\". \n",
    "This book, although written in English, avoids technical jargon like a plague. Simple, non heavy words, and heavy recall value.\n",
    "As Ashneer in his inimitable style says, \"4 shabd se zyada mein baat samjhani pade to bekaar hai phir.\" Ashneer, in this book, takes you through a founder's birth, his life, his highs and lows, and finally a martyr's death.\n",
    "But, as we all know, \"ke picture abhi baaki hai mere dost\", so waiting for the Phoenix to rise yet again, and to take the world by storm, with another idea, another product. We believe in you Ashneer.\n",
    "And we know you'll emerge stronger and with another market disrupter.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5834f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for word in text.split() if word.lower() not in stopwords_nltk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9739114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e004adc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Doglapan Ashneer Grover hands one interesting books I\\'ve ever read favourite. Ashneer\\'s life according full-blown masala Bollywood story, that\\'s one best parts book! Nowhere shy away admitting vulnerability, failures, insecurities. book maybe titled \"Doglapan\", lot \"Sachhai\". book, although written English, avoids technical jargon like plague. Simple, non heavy words, heavy recall value. Ashneer inimitable style says, \"4 shabd se zyada mein baat samjhani pade bekaar hai phir.\" Ashneer, book, takes founder\\'s birth, life, highs lows, finally martyr\\'s death. But, know, \"ke picture abhi baaki hai mere dost\", waiting Phoenix rise yet again, take world storm, another idea, another product. believe Ashneer. know emerge stronger another market disrupter.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ba3434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of of old text :  1012\n"
     ]
    }
   ],
   "source": [
    "print(\"length of of old text : \",len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf20b40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of new text :  756\n"
     ]
    }
   ],
   "source": [
    "print(\"length of new text : \",len(new_text))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "02b65e0c",
   "metadata": {},
   "source": [
    "The steps are\n",
    "    Declare the text\n",
    "    Split the text into words because stop words is a list of words\n",
    "    Change the words to lowercase because the list of stop words is in lowercase\n",
    "    Create a list of all words which are not in the stop words list.\n",
    "    The resulting list is then joined to form the sentence again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9f171e",
   "metadata": {},
   "source": [
    "### 2. spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c63916c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7382b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d15eba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02e78158",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_spacy = s.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9d437f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'but', 'i', 'his', 'serious', '’d', 'whence', 'around', 'cannot', 'where', 'fifteen', 'are', 'may', 'three', 'several', 'amount', 'still', 'anyone', 'have', 'without', 'regarding', 'nine', 'first', 'side', 'has', 'them', 'again', 'upon', 'while', 'been', 'did', 'with', 'therefore', 'although', 'so', 'we', 'former', 'being', 'often', 'above', 'full', 'before', 'meanwhile', 'besides', 'become', 'out', 'please', 'not', 'something', \"'s\", 'himself', 'less', 'whole', 'done', 'since', 'am', 'put', 'others', 'go', 'alone', 'nor', 'anywhere', 'more', \"'ll\", 'unless', 'yourself', 'sometimes', 'whose', 'here', '‘d', 'used', 'do', 'once', 'against', 'her', 'though', 'beside', 'a', 'everyone', 'than', 'really', 'up', 'keep', 'whereupon', 'neither', 'make', 'therein', 'n‘t', '’m', 'yours', 'whither', 'either', 'rather', 'moreover', 'show', 'top', 'else', 'thence', 'nobody', 'give', 'whereas', 'down', 'thereafter', 'becomes', 'this', '‘m', 'during', 'onto', 'it', 'forty', 'whenever', 'whatever', 'why', 'after', 'these', 'hereby', 'along', 'its', 'an', 'front', 'wherever', 'there', 'anything', 'most', 'twelve', 'then', 'in', 'now', '‘s', 'among', 'they', \"'m\", 'take', 'part', 'noone', 'hence', 'beforehand', 'some', 'the', 'otherwise', 'quite', 'much', 'can', 'six', 'none', 'many', 'due', 'everything', 'over', 'somewhere', 'n’t', 'eight', 'twenty', 'throughout', 'ever', 'toward', \"'d\", 'nothing', 'empty', 'below', 'hereafter', 'made', 'hers', 'herself', 'until', 'no', '’re', 'us', 'will', 'she', 'own', \"'ve\", 'myself', 'via', 'within', 'through', 'somehow', 'and', 'various', 'was', 'nowhere', 'any', 'elsewhere', 'what', 'when', 'even', 'thereupon', 'other', 'next', '’ll', '‘ll', 'except', 'or', 'another', 'itself', 'you', 'too', 'at', 'say', 'thus', 'back', 'ca', 'one', 'both', 'see', 'he', 'be', 'should', 'third', 'using', 'move', 'seeming', 'seemed', 'mine', 'just', 'hereupon', 'anyway', 'me', 'by', 'your', 'seem', 'those', 'however', 'fifty', 'latter', 'such', 'to', 'became', 'seems', 'everywhere', 'from', 'whoever', 'never', 'well', 'ours', 'yet', 'for', 'might', 're', '‘ve', '’ve', 'whereby', 'sometime', 'about', 'wherein', 'amongst', 'between', 'their', 'doing', 'mostly', 'towards', 'call', 'afterwards', 'becoming', 'only', 'themselves', 'would', 'always', 'does', 'ourselves', 'already', 'is', 'off', 'must', 'beyond', 'enough', 'very', 'get', \"'re\", 'into', 'who', 'that', 'eleven', 'also', 'indeed', 'four', 'across', 'two', 'whom', 'how', 'hundred', 'had', '‘re', 'together', 'few', 'all', 'someone', 'same', 'of', 'herein', 'as', 'under', 'sixty', 'ten', 'whether', 'on', 'almost', 'name', 'could', '’s', 'behind', 'five', 'last', 'namely', \"n't\", 'anyhow', 'bottom', 'formerly', 'our', 'which', 'him', 'nevertheless', 'every', 'least', 'were', 'thru', 'latterly', 'per', 'whereafter', 'perhaps', 'my', 'each', 'if', 'because', 'further', 'thereby', 'yourselves'}\n"
     ]
    }
   ],
   "source": [
    "print(stopwords_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17070db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of stopwords in spacy library :  326\n"
     ]
    }
   ],
   "source": [
    "print(\"number of stopwords in spacy library : \",len(stopwords_spacy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1319e90c",
   "metadata": {},
   "source": [
    "#### removing stopwords from text by spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff177818",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for word in text.split() if word.lower() not in stopwords_spacy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ffc637b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6f4918df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doglapan Ashneer Grover hands interesting books I've read favourite. Ashneer's life according full-blown masala Bollywood story, that's best parts book! shy away admitting vulnerability, failures, insecurities. book maybe titled \"Doglapan\", lot \"Sachhai\". book, written English, avoids technical jargon like plague. Simple, non heavy words, heavy recall value. Ashneer inimitable style says, \"4 shabd se zyada mein baat samjhani pade bekaar hai phir.\" Ashneer, book, takes founder's birth, life, highs lows, finally martyr's death. But, know, \"ke picture abhi baaki hai mere dost\", waiting Phoenix rise again, world storm, idea, product. believe Ashneer. know you'll emerge stronger market disrupter.\n"
     ]
    }
   ],
   "source": [
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ace40be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old text length :  1012\n"
     ]
    }
   ],
   "source": [
    "print(\"old text length : \",len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c872c25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new text length :  700\n"
     ]
    }
   ],
   "source": [
    "print(\"new text length : \",len(new_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c42ffdb",
   "metadata": {},
   "source": [
    "We can clearly see that the removal of stop words reduced the length of the sentence from 756 to 700,\n",
    "\n",
    "Shorter than NLTK because the spaCy library has more stop words than NLTK.\n",
    "\n",
    "The results, in this case, are quite similar though."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289bebbd",
   "metadata": {},
   "source": [
    "### Gensim \n",
    "Gensim (Generate Similar) is an open-source software library that uses modern statistical machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e454f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "72e57802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8e99bdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'but', 'i', 'his', 'amoungst', 'serious', 'whence', 'around', 'don', 'cannot', 'where', 'fifteen', 'are', 'may', 'three', 'several', 'amount', 'still', 'anyone', 'have', 'without', 'regarding', 'nine', 'first', 'sincere', 'side', 'has', 'them', 'again', 'upon', 'while', 'been', 'did', 'with', 'therefore', 'although', 'so', 'we', 'former', 'being', 'often', 'above', 'full', 'before', 'meanwhile', 'besides', 'doesn', 'become', 'out', 'please', 'not', 'something', 'himself', 'less', 'whole', 'done', 'since', 'inc', 'con', 'am', 'put', 'others', 'go', 'alone', 'nor', 'anywhere', 'more', 'unless', 'yourself', 'whose', 'sometimes', 'here', 'cry', 'used', 'do', 'once', 'against', 'her', 'though', 'beside', 'a', 'everyone', 'than', 'eg', 'up', 'really', 'keep', 'whereupon', 'neither', 'make', 'therein', 'ie', 'yours', 'whither', 'either', 'rather', 'moreover', 'show', 'top', 'else', 'thence', 'nobody', 'give', 'whereas', 'down', 'thereafter', 'becomes', 'this', 'during', 'onto', 'system', 'it', 'forty', 'whenever', 'whatever', 'why', 'after', 'these', 'hereby', 'along', 'its', 'an', 'front', 'wherever', 'there', 'anything', 'most', 'twelve', 'then', 'in', 'now', 'among', 'they', 'take', 'part', 'kg', 'noone', 'hence', 'beforehand', 'some', 'the', 'otherwise', 'quite', 'much', 'can', 'six', 'none', 'many', 'everything', 'due', 'over', 'somewhere', 'eight', 'twenty', 'throughout', 'ever', 'toward', 'nothing', 'empty', 'below', 'hereafter', 'made', 'hers', 'bill', 'herself', 'until', 'mill', 'no', 'us', 'will', 'she', 'own', 'etc', 'myself', 'via', 'within', 'through', 'somehow', 'and', 'various', 'computer', 'was', 'nowhere', 'any', 'what', 'elsewhere', 'when', 'even', 'thereupon', 'thick', 'other', 'next', 'except', 'or', 'another', 'cant', 'itself', 'you', 'at', 'too', 'thus', 'say', 'didn', 'back', 'one', 'both', 'un', 'see', 'thin', 'he', 'be', 'using', 'should', 'third', 'move', 'seeming', 'seemed', 'mine', 'just', 'hereupon', 'anyway', 'me', 'by', 'your', 'seem', 'those', 'however', 'fifty', 'to', 'latter', 'such', 'became', 'seems', 'everywhere', 'from', 'whoever', 'never', 'well', 'ours', 'yet', 'for', 'might', 're', 'whereby', 'sometime', 'about', 'wherein', 'amongst', 'describe', 'between', 'their', 'doing', 'mostly', 'fire', 'found', 'towards', 'call', 'afterwards', 'becoming', 'only', 'themselves', 'ltd', 'would', 'always', 'does', 'ourselves', 'already', 'is', 'off', 'must', 'beyond', 'enough', 'detail', 'very', 'get', 'km', 'who', 'into', 'that', 'eleven', 'also', 'indeed', 'four', 'across', 'whom', 'two', 'how', 'find', 'hundred', 'had', 'together', 'few', 'all', 'someone', 'same', 'of', 'herein', 'as', 'under', 'ten', 'sixty', 'whether', 'fill', 'on', 'almost', 'name', 'could', 'hasnt', 'behind', 'five', 'last', 'namely', 'anyhow', 'bottom', 'formerly', 'our', 'which', 'him', 'nevertheless', 'every', 'least', 'were', 'thru', 'latterly', 'per', 'whereafter', 'perhaps', 'interest', 'my', 'de', 'couldnt', 'each', 'if', 'because', 'further', 'thereby', 'co', 'yourselves'})\n"
     ]
    }
   ],
   "source": [
    "print(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eb34bcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337\n"
     ]
    }
   ],
   "source": [
    "print(len(STOPWORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "64acb06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = remove_stopwords(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "455c2391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doglapan Ashneer Grover hands interesting books I've read favourite. Ashneer's life according full-blown masala Bollywood story, that's best parts book! Nowhere shy away admitting vulnerability, failures, insecurities. His book maybe titled \"Doglapan\", lot \"Sachhai\". This book, written English, avoids technical jargon like plague. Simple, non heavy words, heavy recall value. As Ashneer inimitable style says, \"4 shabd se zyada mein baat samjhani pade bekaar hai phir.\" Ashneer, book, takes founder's birth, life, highs lows, finally martyr's death. But, know, \"ke picture abhi baaki hai mere dost\", waiting Phoenix rise again, world storm, idea, product. We believe Ashneer. And know you'll emerge stronger market disrupter.\n"
     ]
    }
   ],
   "source": [
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "03b0258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of new_text :  727\n"
     ]
    }
   ],
   "source": [
    "print(\"length of new_text : \",len(new_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f501b0",
   "metadata": {},
   "source": [
    "### 4. Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bc1db213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f58367ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'but', 'i', 'his', 'amoungst', 'serious', 'whence', 'around', 'cannot', 'where', 'fifteen', 'are', 'may', 'three', 'several', 'amount', 'still', 'anyone', 'have', 'without', 'nine', 'first', 'sincere', 'side', 'has', 'them', 'again', 'upon', 'while', 'been', 'with', 'therefore', 'although', 'so', 'we', 'former', 'being', 'often', 'above', 'full', 'before', 'meanwhile', 'besides', 'become', 'out', 'please', 'not', 'something', 'himself', 'less', 'whole', 'done', 'since', 'inc', 'am', 'con', 'put', 'others', 'go', 'alone', 'nor', 'anywhere', 'more', 'yourself', 'sometimes', 'whose', 'here', 'cry', 'do', 'once', 'against', 'her', 'though', 'beside', 'a', 'everyone', 'than', 'eg', 'up', 'keep', 'whereupon', 'neither', 'therein', 'ie', 'yours', 'whither', 'either', 'rather', 'moreover', 'show', 'top', 'else', 'thence', 'nobody', 'give', 'whereas', 'down', 'thereafter', 'becomes', 'this', 'during', 'onto', 'system', 'it', 'forty', 'whenever', 'whatever', 'why', 'after', 'these', 'hereby', 'along', 'its', 'an', 'front', 'wherever', 'there', 'anything', 'most', 'twelve', 'then', 'in', 'now', 'among', 'they', 'take', 'part', 'noone', 'hence', 'beforehand', 'some', 'the', 'otherwise', 'much', 'can', 'six', 'none', 'many', 'due', 'everything', 'over', 'somewhere', 'eight', 'twenty', 'throughout', 'ever', 'toward', 'nothing', 'empty', 'below', 'hereafter', 'made', 'bill', 'hers', 'herself', 'until', 'mill', 'no', 'us', 'will', 'she', 'own', 'etc', 'myself', 'via', 'within', 'through', 'somehow', 'and', 'was', 'nowhere', 'any', 'elsewhere', 'what', 'when', 'even', 'thereupon', 'thick', 'other', 'next', 'except', 'or', 'another', 'cant', 'itself', 'you', 'too', 'at', 'thus', 'back', 'one', 'both', 'un', 'see', 'thin', 'he', 'be', 'should', 'third', 'move', 'seeming', 'seemed', 'mine', 'hereupon', 'anyway', 'me', 'by', 'your', 'seem', 'those', 'however', 'fifty', 'latter', 'such', 'to', 'became', 'seems', 'everywhere', 'from', 'whoever', 'never', 'well', 'ours', 'yet', 'for', 'might', 're', 'whereby', 'sometime', 'about', 'wherein', 'amongst', 'describe', 'between', 'their', 'fire', 'mostly', 'found', 'towards', 'call', 'afterwards', 'becoming', 'only', 'themselves', 'ltd', 'would', 'always', 'ourselves', 'already', 'is', 'off', 'must', 'beyond', 'enough', 'detail', 'very', 'get', 'into', 'who', 'that', 'eleven', 'also', 'indeed', 'four', 'across', 'two', 'whom', 'how', 'find', 'hundred', 'had', 'together', 'few', 'all', 'someone', 'same', 'of', 'herein', 'as', 'under', 'sixty', 'ten', 'whether', 'fill', 'on', 'almost', 'name', 'could', 'hasnt', 'behind', 'five', 'last', 'namely', 'anyhow', 'bottom', 'formerly', 'our', 'which', 'him', 'nevertheless', 'every', 'least', 'were', 'thru', 'latterly', 'per', 'whereafter', 'perhaps', 'interest', 'my', 'de', 'couldnt', 'each', 'if', 'because', 'further', 'thereby', 'co', 'yourselves'})\n"
     ]
    }
   ],
   "source": [
    "print(ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0bb060f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n"
     ]
    }
   ],
   "source": [
    "print(len(ENGLISH_STOP_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dc6a2466",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [word for word in text.split() if word.lower() not in ENGLISH_STOP_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4800e8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = \" \".join(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4550a053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doglapan Ashneer Grover hands interesting books I've read favourite. Ashneer's life according full-blown masala Bollywood story, that's best parts book! does shy away admitting vulnerability, failures, insecurities. book maybe titled \"Doglapan\", lot \"Sachhai\". book, written English, avoids technical jargon like plague. Simple, non heavy words, heavy recall value. Ashneer inimitable style says, \"4 shabd se zyada mein baat samjhani pade bekaar hai phir.\" Ashneer, book, takes founder's birth, life, highs lows, finally martyr's death. But, know, \"ke picture abhi baaki hai mere dost\", waiting Phoenix rise again, world storm, idea, product. believe Ashneer. know you'll emerge stronger market disrupter.\n"
     ]
    }
   ],
   "source": [
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "01b0c586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old text length :  1012\n"
     ]
    }
   ],
   "source": [
    "print(\"old text length : \",len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7bb84da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new text length:  705\n"
     ]
    }
   ],
   "source": [
    "print(\"new text length: \",len(new_text))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9d46366",
   "metadata": {},
   "source": [
    "                     nltk   spacy\tgensim\t scikit-learn\n",
    "Words in Library \t 179 \t326 \t337 \t 318\n",
    "Output Length \t     756 \t700 \t727 \t 705"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f35bf3",
   "metadata": {},
   "source": [
    "## Stop Words Custom Lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d6cee8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_nltk.extend(['first','second','third','why'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2718cda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n"
     ]
    }
   ],
   "source": [
    "print(len(stopwords_nltk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b26588",
   "metadata": {},
   "source": [
    "the number of words in the list increased from 179 to 183"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18b0a14",
   "metadata": {},
   "source": [
    "## Remove Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "21a60bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_nltk.remove('why')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "573cf86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    }
   ],
   "source": [
    "print(len(stopwords_nltk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c190b",
   "metadata": {},
   "source": [
    "The number of words in the list reduced from 183 to 182"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9731e78c",
   "metadata": {},
   "source": [
    "## Create Custom List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "57945d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_list = ['was','a','many','in','the','after','of','where','her','they']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7fbfef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [word for word in text.split() if word.lower() not in custom_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "012bae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = \" \".join(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "75e56f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doglapan by Ashneer Grover is hands down one most interesting books I've ever read and now my favourite. Ashneer's life according to me is full-blown masala Bollywood story, and that's one best parts this book! Nowhere does he shy away from admitting his vulnerability, his failures, or his insecurities. His book maybe titled as \"Doglapan\", but has lot \"Sachhai\". This book, although written English, avoids technical jargon like plague. Simple, non heavy words, and heavy recall value. As Ashneer his inimitable style says, \"4 shabd se zyada mein baat samjhani pade to bekaar hai phir.\" Ashneer, this book, takes you through founder's birth, his life, his highs and lows, and finally martyr's death. But, as we all know, \"ke picture abhi baaki hai mere dost\", so waiting for Phoenix to rise yet again, and to take world by storm, with another idea, another product. We believe you Ashneer. And we know you'll emerge stronger and with another market disrupter.\n"
     ]
    }
   ],
   "source": [
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d9903afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961\n"
     ]
    }
   ],
   "source": [
    "print(len(new_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f88e69",
   "metadata": {},
   "source": [
    "by  - Ayush Singh Rawat\n",
    "\n",
    "email - ayush191302013@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da5c65e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
